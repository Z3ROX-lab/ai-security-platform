# ADR-012: StratÃ©gie LLM Souveraine pour Entreprise

## Status
**Accepted**

## Date
2025-01-27

## Context

Les entreprises franÃ§aises et europÃ©ennes manipulant des donnÃ©es sensibles (C4-C5, donnÃ©es personnelles, secrets industriels) doivent respecter des contraintes de souverainetÃ© :

- **RGPD** : DonnÃ©es personnelles protÃ©gÃ©es
- **CLOUD Act** : DonnÃ©es accessibles au gouvernement US si stockÃ©es chez fournisseur amÃ©ricain
- **SecNumCloud** : Qualification ANSSI pour cloud de confiance
- **NIS2** : Directive europÃ©enne cybersÃ©curitÃ©
- **Classification C1-C5** : Niveaux de sensibilitÃ© des donnÃ©es

**ProblÃ¨me** : Les LLMs cloud (OpenAI, Anthropic, Google) envoient les donnÃ©es aux USA â†’ non conforme pour donnÃ©es sensibles.

**Solution** : LLM on-premise avec modÃ¨le open-source souverain.

---

## DÃ©cision

### Architecture retenue

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARCHITECTURE LLM SOUVERAINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚                        DATA CENTER ON-PREMISE                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                    INFERENCE LAYER                       â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚    vLLM     â”‚              â”‚      GPU Nodes      â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  (Serving)  â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  NVIDIA A100/H100   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚             â”‚              â”‚  ou AMD MI300X      â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ â€¢ OpenAI APIâ”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ â€¢ Batching  â”‚                                        â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ â€¢ PagedAttn â”‚                                        â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚   â”‚   â”‚
â”‚  â”‚  â”‚         â”‚                                                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚         â–¼                                                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚              MODÃˆLES MISTRAL                     â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                                                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ Mistral  â”‚  â”‚ Mixtral  â”‚  â”‚ Fine-    â”‚      â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ 7B-v0.3  â”‚  â”‚ 8x7B     â”‚  â”‚ tuned    â”‚      â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚          â”‚  â”‚          â”‚  â”‚ Custom   â”‚      â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ 16GB VRAMâ”‚  â”‚ 100GB    â”‚  â”‚ Model    â”‚      â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                                                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                          â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                              â”‚                                  â”‚   â”‚
â”‚  â”‚                              â–¼                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                    DATA LAYER                            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚   Qdrant    â”‚  â”‚ PostgreSQL  â”‚  â”‚   MinIO     â”‚     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  (Vectors)  â”‚  â”‚   (CNPG)    â”‚  â”‚  (Models)   â”‚     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                          â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  ğŸ”’ NetworkPolicies | PSS | Keycloak RBAC | Audit Logging      â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚  âœ… Aucune donnÃ©e ne quitte l'infrastructure                           â”‚
â”‚  âœ… Conforme RGPD, SecNumCloud, C4-C5                                  â”‚
â”‚  âœ… Audit et contrÃ´le complet                                          â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Part 1: Choix du moteur d'infÃ©rence

### vLLM vs Ollama vs Autres

| CritÃ¨re | vLLM | Ollama | TGI (HuggingFace) | TensorRT-LLM |
|---------|------|--------|-------------------|--------------|
| **Use Case** | Production | Dev/Home lab | Production | Production |
| **Performance** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **GPU Required** | Oui | Non (CPU OK) | Oui | Oui (NVIDIA) |
| **Throughput** | 1000+ tok/s | 5-15 tok/s | 500+ tok/s | 1500+ tok/s |
| **Batching** | Continuous | Non | Dynamic | Continuous |
| **API** | OpenAI-compatible | Propre + OpenAI | OpenAI-compatible | Propre |
| **Multi-GPU** | âœ… Tensor Parallel | âŒ | âœ… | âœ… |
| **Kubernetes** | âœ… Excellent | âœ… Bon | âœ… Bon | âš ï¸ Complexe |
| **Licence** | Apache 2.0 | MIT | Apache 2.0 | Apache 2.0 |

### DÃ©cision : vLLM pour Production

**Pourquoi vLLM ?**

1. **PagedAttention** : Gestion mÃ©moire optimisÃ©e, +24x throughput vs naive
2. **Continuous Batching** : Traite plusieurs requÃªtes simultanÃ©ment
3. **OpenAI-compatible API** : Drop-in replacement, pas de changement de code
4. **Multi-GPU** : Scale horizontal sur plusieurs GPUs
5. **Production-proven** : UtilisÃ© par Anyscale, Databricks, IBM watsonx

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    vLLM vs OLLAMA                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  OLLAMA (Home Lab / Dev)                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                 â”‚
â”‚                                                                          â”‚
â”‚  User 1 â”€â”€â–º [Request] â”€â”€â–º Ollama â”€â”€â–º [Process] â”€â”€â–º Response            â”‚
â”‚  User 2 â”€â”€â–º [Request] â”€â”€â–º [Wait...] â”€â”€â–º [Wait...] â”€â”€â–º Response         â”‚
â”‚  User 3 â”€â”€â–º [Request] â”€â”€â–º [Wait...] â”€â”€â–º [Wait...] â”€â”€â–º Response         â”‚
â”‚                                                                          â”‚
â”‚  âš ï¸ Traitement sÃ©quentiel, un user Ã  la fois                           â”‚
â”‚  âœ… Simple, fonctionne sur CPU                                          â”‚
â”‚                                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                          â”‚
â”‚  vLLM (Production)                                                      â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                       â”‚
â”‚                                                                          â”‚
â”‚  User 1 â”€â”€â–º [Request] â”€â”€â”                                               â”‚
â”‚  User 2 â”€â”€â–º [Request] â”€â”€â”¼â”€â”€â–º vLLM â”€â”€â–º [Batch Process] â”€â”€â–º Responses    â”‚
â”‚  User 3 â”€â”€â–º [Request] â”€â”€â”˜     â”‚                                         â”‚
â”‚                               â”‚                                          â”‚
â”‚                     PagedAttention                                      â”‚
â”‚                     Continuous Batching                                 â”‚
â”‚                     Tensor Parallelism                                  â”‚
â”‚                                                                          â”‚
â”‚  âœ… Traitement parallÃ¨le, haute concurrence                            â”‚
â”‚  âœ… OptimisÃ© GPU, 100x plus rapide                                     â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration vLLM pour Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-mistral
  namespace: ai-inference
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-mistral
  template:
    metadata:
      labels:
        app: vllm-mistral
    spec:
      containers:
        - name: vllm
          image: vllm/vllm-openai:latest
          args:
            - "--model"
            - "mistralai/Mistral-7B-Instruct-v0.3"
            - "--tensor-parallel-size"
            - "1"
            - "--gpu-memory-utilization"
            - "0.9"
            - "--max-model-len"
            - "32768"
          ports:
            - containerPort: 8000
          resources:
            limits:
              nvidia.com/gpu: 1
          volumeMounts:
            - name: model-cache
              mountPath: /root/.cache/huggingface
      volumes:
        - name: model-cache
          persistentVolumeClaim:
            claimName: model-cache-pvc
```

---

## Part 2: Choix du modÃ¨le - Mistral

### Pourquoi Mistral ?

| Aspect | DÃ©tail |
|--------|--------|
| **Origine** | ğŸ‡«ğŸ‡· Entreprise franÃ§aise (Paris, 2023) |
| **Fondateurs** | Arthur Mensch (ex-DeepMind), Guillaume Lample (ex-Meta) |
| **Licence** | Apache 2.0 pour modÃ¨les open-weights |
| **Performance** | Comparable Ã  GPT-3.5, meilleur que LLaMA 2 |
| **Langue** | Excellent en franÃ§ais |
| **CLOUD Act** | âŒ Non applicable (entreprise franÃ§aise) |
| **RGPD** | âœ… Conforme (donnÃ©es restent on-premise) |

### ModÃ¨les Mistral disponibles

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GAMME MISTRAL                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  OPEN-WEIGHTS (Apache 2.0) - Usage commercial âœ…                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                         â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Mistral 7B v0.3                                                  â”‚   â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                â”‚   â”‚
â”‚  â”‚ â€¢ 7 milliards de paramÃ¨tres                                     â”‚   â”‚
â”‚  â”‚ â€¢ VRAM: 16GB (FP16) / 8GB (INT8) / 4GB (INT4)                  â”‚   â”‚
â”‚  â”‚ â€¢ Context: 32K tokens                                           â”‚   â”‚
â”‚  â”‚ â€¢ Use case: Chat, code, assistant gÃ©nÃ©ral                       â”‚   â”‚
â”‚  â”‚ â€¢ GPU: 1x RTX 4090 / A100                                       â”‚   â”‚
â”‚  â”‚ â€¢ Licence: Apache 2.0 âœ…                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Mixtral 8x7B (MoE)                                               â”‚   â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚   â”‚
â”‚  â”‚ â€¢ 47B params total, 13B actifs par infÃ©rence                    â”‚   â”‚
â”‚  â”‚ â€¢ VRAM: 100GB (FP16) / 50GB (INT8) / 26GB (INT4)               â”‚   â”‚
â”‚  â”‚ â€¢ Context: 32K tokens                                           â”‚   â”‚
â”‚  â”‚ â€¢ Use case: Production enterprise, multi-tÃ¢che                  â”‚   â”‚
â”‚  â”‚ â€¢ GPU: 2x A100 80GB / 4x A100 40GB                             â”‚   â”‚
â”‚  â”‚ â€¢ Licence: Apache 2.0 âœ…                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Mixtral 8x22B (MoE)                                              â”‚   â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚   â”‚
â”‚  â”‚ â€¢ 141B params total, 39B actifs par infÃ©rence                   â”‚   â”‚
â”‚  â”‚ â€¢ VRAM: ~300GB                                                   â”‚   â”‚
â”‚  â”‚ â€¢ Context: 64K tokens                                           â”‚   â”‚
â”‚  â”‚ â€¢ Use case: TÃ¢ches complexes, raisonnement avancÃ©              â”‚   â”‚
â”‚  â”‚ â€¢ GPU: 4x H100 80GB                                             â”‚   â”‚
â”‚  â”‚ â€¢ Licence: Apache 2.0 âœ…                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                          â”‚
â”‚  PROPRIÃ‰TAIRES (API Cloud uniquement) - âŒ Pas pour souverainetÃ©       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•        â”‚
â”‚                                                                          â”‚
â”‚  â€¢ Mistral Large (2) - Le plus puissant, cloud only                    â”‚
â”‚  â€¢ Mistral Small - OptimisÃ© latence, cloud only                        â”‚
â”‚  â€¢ Codestral - SpÃ©cialisÃ© code, licence restrictive                    â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Licence Apache 2.0 - Ce qu'elle permet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APACHE 2.0 LICENSE - DROITS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  âœ… AUTORISÃ‰                                                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•                                                             â”‚
â”‚  â€¢ Usage commercial                                                     â”‚
â”‚  â€¢ Modification du modÃ¨le                                               â”‚
â”‚  â€¢ Distribution                                                         â”‚
â”‚  â€¢ Usage privÃ©                                                          â”‚
â”‚  â€¢ Fine-tuning                                                          â”‚
â”‚  â€¢ IntÃ©gration dans produits propriÃ©taires                             â”‚
â”‚  â€¢ CrÃ©ation de dÃ©rivÃ©s                                                  â”‚
â”‚                                                                          â”‚
â”‚  ğŸ“‹ OBLIGATIONS                                                         â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                          â”‚
â”‚  â€¢ Inclure la licence Apache 2.0                                        â”‚
â”‚  â€¢ Indiquer les modifications                                           â”‚
â”‚  â€¢ Conserver les notices de copyright                                   â”‚
â”‚                                                                          â”‚
â”‚  âŒ NON FOURNI                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•                                                           â”‚
â”‚  â€¢ Garantie                                                             â”‚
â”‚  â€¢ ResponsabilitÃ©                                                       â”‚
â”‚  â€¢ Usage de la marque Mistral (sans accord)                            â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Part 3: Fine-tuning

### Pourquoi fine-tuner ?

| Raison | Exemple |
|--------|---------|
| **Domaine spÃ©cifique** | Terminologie mÃ©dicale, juridique, tÃ©lÃ©com |
| **Style d'entreprise** | Ton, format de rÃ©ponse |
| **DonnÃ©es propriÃ©taires** | Documentation interne, procÃ©dures |
| **Performance** | Meilleure prÃ©cision sur cas spÃ©cifiques |
| **SÃ©curitÃ©** | Ã‰viter certains sujets, compliance |

### MÃ©thodes de fine-tuning

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MÃ‰THODES DE FINE-TUNING                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  1. FULL FINE-TUNING (âŒ Rarement utilisÃ©)                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                             â”‚
â”‚  â€¢ EntraÃ®ne TOUS les paramÃ¨tres du modÃ¨le                              â”‚
â”‚  â€¢ Requiert: 8x A100 80GB pour 7B                                       â”‚
â”‚  â€¢ Temps: Jours/semaines                                                â”‚
â”‚  â€¢ CoÃ»t: $$$$$                                                          â”‚
â”‚  â€¢ Risque: Catastrophic forgetting                                      â”‚
â”‚                                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                          â”‚
â”‚  2. LoRA - Low-Rank Adaptation (âœ… RecommandÃ©)                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                           â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚   ModÃ¨le Original (Frozen)     Adaptateurs LoRA (EntraÃ®nÃ©s)    â”‚   â”‚
â”‚  â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚   â”‚                   â”‚       â”‚  Rank-4 Ã  Rank-64       â”‚      â”‚   â”‚
â”‚  â”‚   â”‚   7B paramÃ¨tres   â”‚   +   â”‚  ~0.1% des paramÃ¨tres   â”‚      â”‚   â”‚
â”‚  â”‚   â”‚   (gelÃ©s)         â”‚       â”‚  (entraÃ®nables)         â”‚      â”‚   â”‚
â”‚  â”‚   â”‚                   â”‚       â”‚                         â”‚      â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚   â€¢ Requiert: 1x A100 40GB / 1x RTX 4090                       â”‚   â”‚
â”‚  â”‚   â€¢ Temps: Heures                                               â”‚   â”‚
â”‚  â”‚   â€¢ CoÃ»t: $                                                     â”‚   â”‚
â”‚  â”‚   â€¢ Pas de catastrophic forgetting                              â”‚   â”‚
â”‚  â”‚   â€¢ Adaptateurs fusionnables avec le modÃ¨le original            â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                          â”‚
â”‚  3. QLoRA - Quantized LoRA (âœ… TrÃ¨s efficace)                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                            â”‚
â”‚  â€¢ LoRA + Quantization 4-bit                                           â”‚
â”‚  â€¢ Requiert: 1x RTX 3090 24GB (!)                                      â”‚
â”‚  â€¢ Fine-tune un 7B sur GPU consumer                                    â”‚
â”‚  â€¢ LÃ©gÃ¨re perte de qualitÃ© vs LoRA                                     â”‚
â”‚                                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                          â”‚
â”‚  4. RLHF - Reinforcement Learning from Human Feedback                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                     â”‚
â”‚  â€¢ Aligner le modÃ¨le avec prÃ©fÃ©rences humaines                         â”‚
â”‚  â€¢ TrÃ¨s coÃ»teux en annotation humaine                                  â”‚
â”‚  â€¢ UtilisÃ© par OpenAI, Anthropic                                       â”‚
â”‚  â€¢ Rarement fait en entreprise                                         â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline de fine-tuning recommandÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE FINE-TUNING ENTERPRISE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Ã‰TAPE 1: PrÃ©paration des donnÃ©es                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                       â”‚
â”‚                                                                          â”‚
â”‚  Documents internes â”€â”€â–º Extraction â”€â”€â–º Nettoyage â”€â”€â–º Format JSON       â”‚
â”‚                                                                          â”‚
â”‚  Format: instruction/input/output (Alpaca-style)                        â”‚
â”‚  {                                                                       â”‚
â”‚    "instruction": "Explique la procÃ©dure de remboursement",            â”‚
â”‚    "input": "",                                                         â”‚
â”‚    "output": "La procÃ©dure de remboursement GTT..."                    â”‚
â”‚  }                                                                       â”‚
â”‚                                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                          â”‚
â”‚  Ã‰TAPE 2: Fine-tuning avec LoRA                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                          â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Outils recommandÃ©s:                                             â”‚   â”‚
â”‚  â”‚  â€¢ Hugging Face Transformers + PEFT                             â”‚   â”‚
â”‚  â”‚  â€¢ Axolotl (simplifiÃ©)                                          â”‚   â”‚
â”‚  â”‚  â€¢ LLaMA-Factory                                                â”‚   â”‚
â”‚  â”‚  â€¢ MLflow (tracking expÃ©riences)                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                          â”‚
â”‚  Ã‰TAPE 3: Ã‰valuation                                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                     â”‚
â”‚                                                                          â”‚
â”‚  â€¢ Test set holdout                                                     â”‚
â”‚  â€¢ MÃ©triques: Perplexity, BLEU, ROUGE                                  â”‚
â”‚  â€¢ Ã‰valuation humaine (qualitÃ©, pertinence)                            â”‚
â”‚  â€¢ Tests de sÃ©curitÃ© (jailbreak, prompt injection)                     â”‚
â”‚                                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                          â”‚
â”‚  Ã‰TAPE 4: DÃ©ploiement                                                   â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                    â”‚
â”‚                                                                          â”‚
â”‚  Merge LoRA + Base Model â”€â”€â–º Export GGUF/SafeTensors â”€â”€â–º vLLM          â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Exemple de code fine-tuning avec PEFT/LoRA

```python
"""
Fine-tuning Mistral 7B avec LoRA
Requires: pip install transformers peft datasets accelerate bitsandbytes
"""

from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)
from peft import LoraConfig, get_peft_model, TaskType
from datasets import load_dataset
import torch

# 1. Charger le modÃ¨le de base
model_name = "mistralai/Mistral-7B-Instruct-v0.3"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    load_in_4bit=True  # QLoRA
)

tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token

# 2. Configurer LoRA
lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=16,                      # Rank (4-64)
    lora_alpha=32,             # Scaling factor
    lora_dropout=0.1,
    target_modules=[           # Couches Ã  adapter
        "q_proj",
        "k_proj", 
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj"
    ]
)

model = get_peft_model(model, lora_config)
model.print_trainable_parameters()
# Output: trainable params: 13,631,488 || all params: 7,241,748,480 || trainable%: 0.188%

# 3. Charger les donnÃ©es
dataset = load_dataset("json", data_files="training_data.json")

def format_prompt(example):
    return f"""<s>[INST] {example['instruction']}
{example['input']} [/INST] {example['output']}</s>"""

def tokenize(example):
    return tokenizer(
        format_prompt(example),
        truncation=True,
        max_length=2048,
        padding="max_length"
    )

tokenized_dataset = dataset.map(tokenize)

# 4. EntraÃ®ner
training_args = TrainingArguments(
    output_dir="./mistral-7b-finetuned",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,
    warmup_steps=100,
    logging_steps=10,
    save_steps=100,
    fp16=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)
)

trainer.train()

# 5. Sauvegarder
model.save_pretrained("./mistral-7b-lora-adapter")

# 6. Merge et export (optionnel)
from peft import PeftModel

base_model = AutoModelForCausalLM.from_pretrained(model_name)
merged_model = PeftModel.from_pretrained(base_model, "./mistral-7b-lora-adapter")
merged_model = merged_model.merge_and_unload()
merged_model.save_pretrained("./mistral-7b-merged")
```

---

## Part 4: Architecture complÃ¨te pour GTT

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARCHITECTURE COMPLÃˆTE GTT                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚                         DATA CENTER GTT (France)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚                      OPENSHIFT CLUSTER                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                                                          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  Open WebUI â”‚  â”‚   Qdrant    â”‚  â”‚   MLflow    â”‚     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  (Chat UI)  â”‚  â”‚  (Vectors)  â”‚  â”‚ (Tracking)  â”‚     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚         â”‚                â”‚                               â”‚   â”‚   â”‚
â”‚  â”‚  â”‚         â”‚                â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚   â”‚
â”‚  â”‚  â”‚         â”‚                â”‚         â”‚  Keycloak   â”‚      â”‚   â”‚   â”‚
â”‚  â”‚  â”‚         â”‚                â”‚         â”‚   (SSO)     â”‚      â”‚   â”‚   â”‚
â”‚  â”‚  â”‚         â”‚                â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚   â”‚
â”‚  â”‚  â”‚         â”‚                â”‚                               â”‚   â”‚   â”‚
â”‚  â”‚  â”‚         â–¼                â–¼                               â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                    vLLM                          â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚              (Inference Server)                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                                                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚           MODÃˆLES MISTRAL                 â”‚   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚                                           â”‚   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  â”‚ Mixtral    â”‚    â”‚ Mistral    â”‚        â”‚   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  â”‚ 8x7B       â”‚    â”‚ 7B-GTT     â”‚        â”‚   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  â”‚ (General)  â”‚    â”‚ (Fine-tuned)â”‚       â”‚   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚                                           â”‚   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                       â”‚                          â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                       â–¼                          â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚              â”‚  GPU Cluster  â”‚                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚              â”‚  4x A100 80GB â”‚                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                                                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                 DATA LAYER                       â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                                                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ PostgreSQL â”‚  â”‚   MinIO    â”‚  â”‚  HashiCorp â”‚â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚   (CNPG)   â”‚  â”‚  (Models)  â”‚  â”‚   Vault    â”‚â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                                                  â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                          â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  SÃ‰CURITÃ‰                                                       â”‚   â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•                                                        â”‚   â”‚
â”‚  â”‚  â€¢ NetworkPolicies (isolation rÃ©seau)                           â”‚   â”‚
â”‚  â”‚  â€¢ Pod Security Standards (restricted)                          â”‚   â”‚
â”‚  â”‚  â€¢ Keycloak RBAC (qui accÃ¨de Ã  quoi)                           â”‚   â”‚
â”‚  â”‚  â€¢ HashiCorp Vault (secrets)                                    â”‚   â”‚
â”‚  â”‚  â€¢ NeMo Guardrails (sÃ©curitÃ© LLM)                              â”‚   â”‚
â”‚  â”‚  â€¢ Audit Logging (traÃ§abilitÃ©)                                  â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Part 5: Comparaison coÃ»ts

### Cloud vs On-Premise

| Aspect | Cloud (OpenAI) | On-Premise (Mistral) |
|--------|----------------|----------------------|
| **CoÃ»t initial** | $0 | $200k-500k (GPUs) |
| **CoÃ»t mensuel (1M tokens/jour)** | ~$3,000 | ~$2,000 (Ã©lectricitÃ©, maintenance) |
| **Break-even** | - | 6-12 mois |
| **SouverainetÃ©** | âŒ Non | âœ… Oui |
| **Fine-tuning** | âš ï¸ LimitÃ© | âœ… Total |
| **Latence** | ~500ms | ~100ms |
| **ScalabilitÃ©** | âœ… Infinie | âš ï¸ LimitÃ©e au hardware |

### Estimation GPU pour production

| ModÃ¨le | GPU Minimum | GPU RecommandÃ© | CoÃ»t GPU |
|--------|-------------|----------------|----------|
| Mistral 7B | 1x A100 40GB | 2x A100 40GB | ~$15k |
| Mixtral 8x7B | 2x A100 80GB | 4x A100 80GB | ~$60k |
| Mixtral 8x22B | 4x H100 80GB | 8x H100 80GB | ~$250k |

---

## ConsÃ©quences

### Positives

- âœ… SouverainetÃ© totale des donnÃ©es
- âœ… ConformitÃ© RGPD, SecNumCloud, C4-C5
- âœ… ContrÃ´le complet sur le modÃ¨le
- âœ… Fine-tuning possible
- âœ… Pas de dÃ©pendance cloud Ã©tranger
- âœ… CoÃ»t prÃ©visible Ã  long terme

### NÃ©gatives

- âš ï¸ Investissement initial important (GPUs)
- âš ï¸ Expertise ML/Ops requise
- âš ï¸ Maintenance infrastructure
- âš ï¸ ScalabilitÃ© limitÃ©e au hardware

### Risques et mitigations

| Risque | ProbabilitÃ© | Impact | Mitigation |
|--------|-------------|--------|------------|
| GPU shortage | Moyenne | Haut | Commander tÃ´t, contrats long terme |
| ModÃ¨le obsolÃ¨te | Faible | Moyen | Upgrade path clair, LoRA portable |
| Panne GPU | Moyenne | Haut | Redondance, spare GPUs |
| CompÃ©tences ML | Moyenne | Moyen | Formation, partenariats |

---

## RÃ©fÃ©rences

- [Mistral AI Documentation](https://docs.mistral.ai/)
- [vLLM Documentation](https://docs.vllm.ai/)
- [Hugging Face PEFT](https://huggingface.co/docs/peft)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [QLoRA Paper](https://arxiv.org/abs/2305.14314)
- [ANSSI SecNumCloud](https://www.ssi.gouv.fr/entreprise/qualifications/prestataires-de-services-de-confiance-qualifies/prestataires-de-service-dinformatique-en-nuage-secnumcloud/)
- [RGPD](https://www.cnil.fr/fr/rgpd-de-quoi-parle-t-on)
- [CLOUD Act](https://www.congress.gov/bill/115th-congress/house-bill/4943)
