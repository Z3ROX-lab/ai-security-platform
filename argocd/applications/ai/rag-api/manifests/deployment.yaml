# =============================================================================
# RAG API Kubernetes Manifests (Phase 6 + Guardrails Integration)
# =============================================================================

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: rag-api-config
  namespace: ai-inference
  labels:
    app: rag-api
data:
  # Qdrant
  QDRANT_URL: "http://qdrant.ai-inference.svc.cluster.local:6333"
  QDRANT_COLLECTION: "documents"
  
  # Ollama
  OLLAMA_URL: "http://ollama.ai-inference.svc.cluster.local:11434"
  EMBEDDING_MODEL: "nomic-embed-text"
  LLM_MODEL: "mistral:7b-instruct-v0.3-q4_K_M"
  
  # RAG settings
  CHUNK_SIZE: "1000"
  CHUNK_OVERLAP: "100"
  TOP_K: "3"
  
  # Guardrails (Phase 7a integration)
  GUARDRAILS_URL: "http://guardrails-api.ai-inference.svc.cluster.local:8000"
  GUARDRAILS_ENABLED: "true"
  
  # Service
  PORT: "8000"
  LOG_LEVEL: "INFO"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: rag-api-script
  namespace: ai-inference
  labels:
    app: rag-api
data:
  requirements.txt: |
    fastapi>=0.109.0
    uvicorn>=0.27.0
    pydantic>=2.5.0
    requests>=2.31.0

  startup.sh: |
    #!/bin/bash
    set -e
    
    echo "ðŸ“¦ Installing dependencies..."
    pip install --no-cache-dir -q -r /app/requirements.txt
    
    echo "ðŸš€ Starting RAG API v2 (with Guardrails)..."
    cd /app
    exec python rag_api.py serve

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rag-api
  namespace: ai-inference
  labels:
    app: rag-api
    app.kubernetes.io/name: rag-api
    app.kubernetes.io/component: api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: rag-api
  template:
    metadata:
      labels:
        app: rag-api
        app.kubernetes.io/name: rag-api
    spec:
      containers:
      - name: rag-api
        image: python:3.11-slim
        command: ["/bin/bash", "/app/startup.sh"]
        ports:
        - name: http
          containerPort: 8000
          protocol: TCP
        envFrom:
        - configMapRef:
            name: rag-api-config
        env:
        - name: QDRANT_API_KEY
          valueFrom:
            secretKeyRef:
              name: rag-api-qdrant-key
              key: api-key
              optional: true
        volumeMounts:
        - name: code
          mountPath: /app/rag_api.py
          subPath: rag_api.py
        - name: startup
          mountPath: /app/startup.sh
          subPath: startup.sh
        - name: startup
          mountPath: /app/requirements.txt
          subPath: requirements.txt
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        startupProbe:
          httpGet:
            path: /
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          failureThreshold: 12
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 30
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
      volumes:
      - name: code
        configMap:
          name: rag-api-code
      - name: startup
        configMap:
          name: rag-api-script
          defaultMode: 0755

---
apiVersion: v1
kind: Service
metadata:
  name: rag-api
  namespace: ai-inference
  labels:
    app: rag-api
spec:
  type: ClusterIP
  selector:
    app: rag-api
  ports:
  - name: http
    port: 8000
    targetPort: 8000
    protocol: TCP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: rag-api
  namespace: ai-inference
  labels:
    app: rag-api
  annotations:
    cert-manager.io/cluster-issuer: "ai-platform-ca-issuer"
    traefik.ingress.kubernetes.io/router.tls: "true"
spec:
  ingressClassName: traefik
  tls:
  - hosts:
    - rag.ai-platform.localhost
    secretName: rag-api-tls
  rules:
  - host: rag.ai-platform.localhost
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: rag-api
            port:
              number: 8000
