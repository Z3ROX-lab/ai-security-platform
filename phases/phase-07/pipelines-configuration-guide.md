# Open WebUI Pipelines - Configuration Guide

## Overview

Ce guide documente l'intÃ©gration des Guardrails LLM Guard dans Open WebUI via le systÃ¨me Pipelines.

| Composant | RÃ´le |
|-----------|------|
| **Open WebUI** | Interface chat |
| **Pipelines** | Serveur de plugins/filtres |
| **LLM Guard Filter** | Notre pipeline custom |
| **Guardrails API** | Backend ML (scanners) |

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OPEN WEBUI + PIPELINES + GUARDRAILS                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  User Message                                                               â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â–¼                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         OPEN WEBUI                                   â”‚   â”‚
â”‚  â”‚                  chat.ai-platform.localhost                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â–¼                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      PIPELINES SERVER                                â”‚   â”‚
â”‚  â”‚              open-webui-pipelines.ai-apps.svc:9099                   â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚              LLM GUARD FILTER PIPELINE                         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                                â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  inlet()  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  POST /scan/input                                        â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚     â”‚                                                    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚     â–¼                                                    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”‚           GUARDRAILS API                        â”‚    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”‚   guardrails-api.ai-inference.svc:8000          â”‚    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”‚                                                 â”‚    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”‚   â€¢ PromptInjection Scanner                     â”‚    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”‚   â€¢ Toxicity Scanner                            â”‚    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”‚   â€¢ Secrets Scanner                             â”‚    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â–¼                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  BLOCKED? â”€â”€â–º Yes â”€â”€â–º Return Error ğŸ›¡ï¸                         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     No                                                         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â–¼                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Continue to LLM (Ollama)                                      â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â–¼                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  outlet() â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  POST /scan/output                                       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â–¼                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  PII Redacted? â”€â”€â–º <PERSON>, <EMAIL>, <SSN>                   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚     â”‚                                                          â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚        â”‚                                                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                                                                   â”‚
â”‚           â–¼                                                                   â”‚
â”‚     Safe Response to User                                                    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## PrÃ©requis

| Composant | Status |
|-----------|--------|
| Guardrails API dÃ©ployÃ© | `kubectl get pods -n ai-inference -l app=guardrails-api` |
| Open WebUI dÃ©ployÃ© | `kubectl get pods -n ai-apps -l app.kubernetes.io/instance=open-webui` |
| Pipelines server | `kubectl get pods -n ai-apps -l app.kubernetes.io/component=open-webui-pipelines` |

## Configuration

### 1. VÃ©rifier la connexion Pipelines

```bash
# Test depuis Open WebUI
kubectl exec -it -n ai-apps open-webui-0 -- curl -s \
  -H "Authorization: Bearer 0p3n-w3bu!" \
  http://open-webui-pipelines.ai-apps.svc.cluster.local:9099/
```

RÃ©sultat attendu : `{"status":true}`

### 2. Configurer la connexion dans Open WebUI

1. Aller sur https://chat.ai-platform.localhost
2. Se connecter via Keycloak
3. **Admin Panel** â†’ **Settings** â†’ **Connections**
4. Dans "Manage OpenAI API Connections", vÃ©rifier :
   - URL : `http://open-webui-pipelines.ai-apps.svc.cluster.local:9099`
   - API Key : `0p3n-w3bu!`
5. **Save**

### 3. Uploader le Pipeline

1. **Admin Panel** â†’ **Settings** â†’ **Pipelines**
2. Cliquer "Upload Pipeline"
3. SÃ©lectionner `llmguard_filter_pipeline.py`
4. **Save**

### 4. VÃ©rifier le chargement

```bash
kubectl logs -n ai-apps deployment/open-webui-pipelines --tail=20
```

RÃ©sultat attendu :
```
Loaded module: llmguard_filter_pipeline
[LLM Guard] Started - URL: http://guardrails-api.ai-inference.svc.cluster.local:8000
```

## Pipeline Code

Le fichier `llmguard_filter_pipeline.py` :

```python
"""
title: LLM Guard Filter Pipeline
author: Z3ROX
version: 2.0
license: MIT
description: Calls Guardrails API for prompt injection detection and PII filtering
"""

from typing import List, Optional
from pydantic import BaseModel
import requests

class Pipeline:
    class Valves(BaseModel):
        pipelines: List[str] = ["*"]  # Apply to all models
        priority: int = 0
        guardrails_url: str = "http://guardrails-api.ai-inference.svc.cluster.local:8000"
        enabled: bool = True
        block_on_detection: bool = True

    def __init__(self):
        self.type = "filter"
        self.id = "llmguard_filter"
        self.name = "LLM Guard Security Filter"
        self.valves = self.Valves()

    async def inlet(self, body: dict, user: Optional[dict] = None) -> dict:
        """Scan input for prompt injection before LLM"""
        # ... calls POST /scan/input
        
    async def outlet(self, body: dict, user: Optional[dict] = None) -> dict:
        """Scan output for PII after LLM"""
        # ... calls POST /scan/output
```

## Configuration des Valves

Les "Valves" sont les paramÃ¨tres configurables du pipeline :

| Valve | Default | Description |
|-------|---------|-------------|
| `pipelines` | `["*"]` | ModÃ¨les ciblÃ©s (* = tous) |
| `priority` | `0` | PrioritÃ© d'exÃ©cution |
| `guardrails_url` | `http://guardrails-api...` | URL du backend |
| `enabled` | `true` | Activer/dÃ©sactiver |
| `block_on_detection` | `true` | Bloquer ou juste logger |

Pour modifier les valves :
1. **Admin Panel** â†’ **Settings** â†’ **Pipelines**
2. Cliquer sur le pipeline "LLM Guard Security Filter"
3. Modifier les paramÃ¨tres
4. **Save**

## Persistence

| Ã‰lÃ©ment | Stockage | PersistÃ© |
|---------|----------|----------|
| Pipeline code | PVC `open-webui-pipelines` (2Gi) | âœ… Oui |
| Valves config | PVC `open-webui-pipelines` | âœ… Oui |
| Logs | stdout | âŒ Non |

```bash
# VÃ©rifier le stockage
kubectl get pvc -n ai-apps | grep pipelines

# Voir les fichiers persistÃ©s
kubectl exec -it -n ai-apps deployment/open-webui-pipelines -- \
  ls -la /app/pipelines/
```

## Monitoring

### Logs en temps rÃ©el

```bash
kubectl logs -n ai-apps deployment/open-webui-pipelines -f
```

### Logs avec filtrage LLM Guard

```bash
kubectl logs -n ai-apps deployment/open-webui-pipelines -f | grep "LLM Guard"
```

### Exemple de logs

```
[LLM Guard] User: admin, Valid: false, Risk: 1.0
[LLM Guard] User: john, Valid: true, Risk: -1.0
[LLM Guard] PII redacted from response
```

## Troubleshooting

| ProblÃ¨me | Cause | Solution |
|----------|-------|----------|
| "Pipelines Not Detected" | API Key manquante | Ajouter `0p3n-w3bu!` dans Connections |
| Pipeline non chargÃ© | Erreur de syntaxe | VÃ©rifier logs pipelines |
| Guardrails API unreachable | Service down | `kubectl get pods -n ai-inference` |
| Messages non bloquÃ©s | `enabled: false` | VÃ©rifier les Valves |

### Test de connectivitÃ©

```bash
# Pipelines â†’ Guardrails
kubectl exec -it -n ai-apps deployment/open-webui-pipelines -- \
  curl -s http://guardrails-api.ai-inference.svc.cluster.local:8000/health
```

## SÃ©curitÃ©

| Aspect | ImplÃ©mentation |
|--------|----------------|
| API Key Pipelines | `0p3n-w3bu!` (changer en prod) |
| Network | ClusterIP only (pas d'ingress) |
| Code execution | Warning : ne pas charger de pipelines non trusted |

## RÃ©fÃ©rences

- [Open WebUI Pipelines Docs](https://docs.openwebui.com/features/pipelines/)
- [Pipelines GitHub](https://github.com/open-webui/pipelines)
- [LLM Guard Examples](https://github.com/open-webui/pipelines/tree/main/examples/filters)

---

**Date:** 2026-02-03
**Author:** Z3ROX - AI Security Platform
**Version:** 1.0.0
